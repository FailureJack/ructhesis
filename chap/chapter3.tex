\chapter{基于近存计算硬件的矩阵向量乘软件优化}
基于在第二章介绍的GEMV的通用两种方法，直接使用float32数据格式进行GEMV的计算的性能非常差，原因是UPMEM硬件不支持浮点数的算术运算而使用软件模拟，其性能大约是int32数据类型格式的算术吞吐的十分之一\cite{BenchmarkingMutlu}，因此需要考虑量化。在上一章提到，浮点量化格式往往优于定点量化\cite{ZeroQuantFP}；同时测试表明UPMEM的访存较计算更快，计算访存比仅有1:4\cite{BenchmarkingMutlu}，因此非常适合用访存换计算。基于上面的两点我们使用基于FP8数据格式\cite{FP8}的查找表算法。量化的大致思路是使用机器学习的方式以少量的校准数据集调整权重参数以适应基于LUT的GEMV内核。针对反向传播中LUT不可导的问题，可以使用直通估计器（Straight-Through Estimator，STE）解决\cite{NonuniformQuant}（STE简单来说就是跳过LUT自身的梯度下降，将误差直通传递到上一层，通过调整上一层的矩阵权重来实现误差最小化，这是一种非均匀量化的手段）。受篇幅限制，本文将不讨论具体的量化方法而专注于设计通用的矩阵向量乘内核。此外为了和Llama2-7B保持一致，没有特别说明，本章中涉及到的权重矩阵的维度皆为$4096\times 4096$，同时本章所有讨论的优化都是建立在单个DPU的推理优化。因此单个DPU的GEMV内核的正常输入为4096维度FP8数据格式的激活向量，4096维度FP8数据格式的权重方阵，最终计算得到的结果为4096维度的结果向量。

本章将基于量化后FP8数据格式的查找表算法优化GEMV算子，主要分两个层次进行优化，首先优化WRAM的数据局部性，减少MRAM访存；其次优化寄存器的数据局部性，减少WRAM的访存。

\section{基于多级存储的查找表分块算法}
UPMEM的MRAM访问是通过DMA引擎，速度较慢，并且只在大批量数据传输时带宽较高，针对该硬件特性，本节针对存储层级MRAM做访存优化，提高WRAM的数据局部性。

\subsection{矩阵向量乘查找表基础}
查找表（Look Up Table，LUT）是非常典型的存储换计算的技巧，常常被用在某些边端设备或者计算能力有限的硬件上以支持复杂计算。由于UPMEM硬件本身较弱的计算能力，以及较低的计算访存比，非常适合使用访存换计算的方法。一般意义上的查找表就是对于函数$f(x_1,x_2,\cdots,x_n)=y$，在一定的定义域范围和精度内穷举所有自变量的组合，并提前计算得到每种组合对应的函数值，制作成一张映射表，此后的函数计算无需计算而只需查表即可。由于计算机只能离散有限地表示数值，每种特定位宽的数是天然可穷举的，例如对于$n bit$的数作为自变量，其本身有$2^n$种不同的数值，两个$n bit$的数作为自变量，则有$2^{2n}$个不同的组合。

\begin{figure}[!htbp]
	\centering
    \includegraphics[width=0.9\textwidth]{figures/LUT.pdf}
	\caption{基于查找表的矩阵向量乘}
    \label{LUT}
\end{figure}

这里举例GEMV的8bit乘法查找表的设计，如图\ref{LUT}所示，其中有一张数据类型为uint8的乘法查找表（为了直观采用uint8数据格式）。由于两个操作数都为8bit，因此输入一共有$256\times 256=2^{16}$种组合，因此可以提前构建一个256行256列二维数组存储查找表LUT，第一个操作数的数值代表行索引，第二个操作数的数值代表列索引，行索引和列索引交叉索引到的元素值为两个操作数的乘积。例如在进行GEMV运算时，要计算激活向量（Activation Vector）中某个值为16的元素和权重矩阵中某个值为8的元素的乘积，现只需要访问提前构建好的二维数组（查找表）的第16行第8列的元素即可，得到答案为128，再加到结果向量（Result Vector）的对应位置上。当然这里加法计算同样可以通过构建一张8bit的加法查找表消除。这样，8位宽下任意数据格式的任意二元算术运算都可以按照上述的查表方式将计算转换为访存。同时上述访存过程仅仅涉及最简单的数组索引计算，几乎能够得到所有硬件的支持，从而降低了对硬件算术能力的要求。

上述乘法查找表的构建存在冗余，因为乘法满足交换律，因此上述$256\times 256$的矩阵只需要保存上三角或下三角即可。甚至能够进一步将8bit的乘法拆成多步4bit的乘法、加法和移位操作，但这两种做法无疑都会增加计算复杂度，对于在UPMEM上需要频繁访问的查找表而言是不合适的。同时查找表能够按照行划分成为子表，例如上述uint8的乘法查找表，当能够确定某个操作数的变化范围在[0,64)时，只需要上述查找表的前64行即可满足计算，即每一行和多行的组合都是属于8bit乘法查找表的子查找表，当空间受限时，可以按需载入子查找表。在此我们特别约定：1）查找表的大小和构建方式都如上述所描述，n bit的二元运算查找表表项为$2^{2n}$；2）二元运算查找表通过两个索引（分别是行列索引）确定查找值，约定这里的索引在后文称作索引值（row/col index），查表得到的值为元素值（element）；3）后文如果没有特别说明，子查找表指的是原查找表二维数组的不同行的组合，即确定行索引值的范围的子表。

\subsection{分块载入查找表卸载乘法}
直接使用8bit乘法查找表的方法在UPMEM中卸载GEMV计算存在诸多问题，首当其冲的就是WRAM的空间限制：由于查找表在执行GEMV运算时需要频繁访问，因此必须要将其载入WRAM高速内存中才会有较好的性能。然而8bit的查找表光是表项就有$256x256=2^{16}=64K$项，如果按照表中每个元素刚好占用1字节，则查找表需要占用空间64KB，而WRAM的容量只有64KB，除了用户数据之外至少需要为各个线程的堆栈留存一部分空间，因此无法将整个查找表载入WRAM。

解决办法就是分块载入查找表，每次只执行数据范围落在当前载入的子查找表覆盖的范围内的计算。但是此时需要注意的一点就是数据的重用性：权重矩阵无法一次性全部载入WRAM，从MRAM载入WRAM的带宽远低于WRAM与核心交互的带宽，分多次载入子查找表后需要避免因为计算不完整而重复载入矩阵。基于上述考虑，我们设计了基于分块载入查找表卸载GEMV中的乘法的算法，具体如图\ref{LUTBlock}所示，激活向量（Activation Vector）和结果向量（Result Vector）完整载入WRAM中，将查找表拆分成16个子查找表，行索引范围被划分为在$[0-15),[16-31),\cdots,[240,256)$16个区间。

\begin{figure}[!htbp]
	\centering
    \includegraphics[width=0.9\textwidth]{figures/LUTBlock.pdf}
	\caption{分块载入查找表卸载GEMV中的乘法}
    \label{LUTBlock}
\end{figure}

该算法需要进行子查找表个数次迭代，每次迭代流程大致为：将子查找表载入WRAM中，遍历激活向量，对于每个元素判断其值是否在当前子查找表的行索引值区间内，对于满足要求的元素，将该元素所对应的权重矩阵（Weight Matrix）的行向量从MRAM载入WRAM，执行查表乘法计算并加到结果向量上；对于不满足要求的元素直接跳过，等待下一次迭代再进行判断。如此一来完全没有将数据重复地从MRAM搬移到WRAM中，无论是查找表还是权重矩阵，都只从MRAM中搬移到WRAM中一次，实现了非常良好的WRAM数据局部性。

\subsection{基于数制映射表卸载加法}
想要完整卸载GEMV算子的所有计算仅仅使用上述分块查找表卸载乘法远远不够，上述方法虽然使用分块载入的方式解决空间上的限制，但是在计算加法时无法简单套用类似的思路：由于使用的数制是FP8，硬件加法无法支持，同时由于累加的操作特性，FP8加法的所在查找表区间是动态变化的，无法事先静态地确定并载入子查找表，直接从MRAM中读取性能就会非常差。一种方式是直接使用软件模拟：FP8常用的有两种格式\cite{FP8}，如表\ref{FP8Format}所示，我们选用E4M3格式的FP8进行推理，因其相较于E5M2具有更高的精度（E5M2相较于E4M3拥有更高的动态范围更适合训练）。其数据格式并不完全符合IEEE754，取消了无穷的表示缩减了NaN的表示范围以容纳更多规格化数，其他部分均符合IEEE754的标准。
    
\begin{table}[!htbp]
    \caption{FP8常用两种格式二进制细节}
    \label{FP8Format}
    \begin{tabular}{lll}
        \toprule
        & E4M3 & E5M2 \\ 
        \midrule
        Exponent bias & 7 & 15 \\
        Infinities & N/A & S.11111.00\textsubscript{2} \\
        NaN & S.11111.11\textsubscript{2} & S.11111.\{01, 10, 11\}\textsubscript{2} \\
        Zeros & S.0000.00\textsubscript{2} & S.00000.00\textsubscript{2} \\
        Max normal & S.1111.10\textsubscript{2} = 1.75 * 2\textsuperscript{8} = 448 & S.11110.11\textsubscript{2} = 1.75 * 2\textsuperscript{15} = 57,344 \\
        Min normal & S.0001.00\textsubscript{2} = 2\textsuperscript{-6} & S.000001.00\textsubscript{2} = 2\textsuperscript{-14} \\
        Max subnormal & S.0000.11\textsubscript{2} = 0.875 * 2\textsuperscript{-6} & S.000000.11\textsubscript{2} = 0.75 * 2\textsuperscript{-14} \\
        Min subnormal & S.0000.01\textsubscript{2} = 2\textsuperscript{-9} & S.000000.01\textsubscript{2} = 2\textsuperscript{-16} \\ 
        \bottomrule
    \end{tabular}
\end{table}

如果直接使用软件模拟，计算两个浮点数的流程的大致为：对阶、尾数求和、规格化、舍入、溢出处理，虽然不用处理无穷等特殊情况，但是上述几个步骤中涉及到大量的移位操作和逻辑操作，由于UPMEM的一个周期至多只能执行一条指令\cite{UPMEMHotChips}，因此这些位运算和逻辑运算指令开销不能忽视，而且由于规格和非规格数的区别存在大量的条件判断和跳转语句，同样非常影响性能。

分析量化大模型的推理流程，以W8A8的量化为例，在进行线性层推理时，会先将8bit量化的权重和激活解量化到16bit，再调用矩阵乘法库中的16bit矩阵向量乘算子，得到16bit的结果，再转换回8bit的结果向量传递给下一个算子。受此启发，
可以将E4M3格式的FP8展开成int32，使用int32进行加法计算和中间结果的保存（硬件不支持int32乘法但是支持加法），在得到最终的结果向量后再转回FP8数制以便后续的传输。具体的展开形式可以很简单，E4M3的符号位不变置于int32的符号位，同时根据指数位置判断该数是否为规格化数，若是规格化数，则需要将尾数的低三位前面添1形成4位尾数；若不是规格化数，则正常取尾数。然后假设指数部分的值为e，将尾数左移$max(e-1，0)$位即可。如图\ref{LUTBS}所示，FP8数0 0010 110转为int32为0...11100，FP8数0 0000 110转为int32为0...110，二者相加得0...100010，这个时候反转回FP8应该首先判断是否为规格数，显然该数为规格化数，需要将int32数右移直至前导第一个1到最低第4位上（计算舍入）即可。

但其实同样可以使用一张数制映射表代替上述复杂的逻辑操作，如图\ref{LUTBS}中的MapLUT，是一个表项为256的一元映射查找表，提前将FP8展开存储在该张映射表中，在计算时展开操作就可以换为查表操作。更进一步，原本的乘法查找表元素为单字节FP8，现在将其替换为其对int32的映射项，变为四字节。这样查询出来的乘积就是int32的展开格式，直接加到同样每个元素扩展为32位的结果向量中。最后，基于查找表MapLUT再通过二分查找将结果向量中的每个元素还原成FP8以便后续的传输。

\begin{figure}[!htbp]
	\centering
    \includegraphics[width=0.9\textwidth]{figures/BinarySearch.pdf}
	\caption{数制映射表卸载GEMV中的加法}
    \label{LUTBS}
\end{figure}

在查找的过程中，可能会遇到舍入问题，即计算出来的元素值无法精准匹配查找表中的元素，其原因是使用int32进行加法运算时保留了相当的精度没有舍入，这个时候会出现待查找的值处于查找表两个相邻元素值之间，如图\ref{LUTBS}所示，为了简化计算加速查找我们直接选择索引值较小的那个数作为查找结果：一方面转为int32进行中间结果的加法运算相对于直接使用FP8计算保留了相当大精度，这里只是将最终结果进行转换因此精度损失整体来讲不大；另一方面精度损失仍然可以通过离线的基于机器学习的量化工作优化消除。这种舍入方式我们这里称之为向最小索引值舍入（Round to Smallest Index），这种舍入其实本质和IEEE754标准的向零舍入（Round toward Zero）是同一种舍入规则。

\subsection{算法小结}

\begin{algorithm}[!htbp]
    \caption{基于多级存储的查找表分块算法（LUT-M）}
    \label{LUT-M}
    \begin{algorithmic}[1]
        \Require $Vector[M], Matrix[M][N], LUT[256][256], MapLUT[256]$; % input
        \Ensure $Result\_8[N]$; % output

        \State $\textbf{define}\; SubLUT[16][256],\;MatRow[N],\;Result\_32[N]$

        \For{$i \gets 0$ \textbf{to} $15$}
            \State $\textbf{mram\_read}(SubLUT, LUT[16i \cdots 16i + 15], 16K)$
            \Comment{\textcolor{blue}{parallel read}}
            \For{$j \gets 0$ \textbf{to} $M - 1$}
                \If{$Vector[j] \;\textbf{not in}\; [16i, 16i+15]$}
                    \State \textbf{continue}
                \EndIf
                \State $\textbf{mram\_read}(MatRow, Matrix[j], N)$
                \Comment{\textcolor{blue}{parallel in N for each tasklet}}
                
                \For{$k \gets 0$ \textbf{to} $N-1$}
                \Comment{\textcolor{blue}{parallel in N for each tasklet}}
                    \State $Result[k] \gets Result[k] + SubLUT[Vector[j] \& \text{0xF}][MatRow[k]]$
                \EndFor
            \EndFor
        \EndFor

        % 调用二分查找函数
        \State $Result\_8 \gets \textbf{BinarySearch}(Result\_32, MapLUT)$
        \Comment{\textcolor{blue}{parallel in N}}
        \State \Return $Result\_8$
    \end{algorithmic}
\end{algorithm}

至此，可以完全卸载GEMV算子的全部运算到UPMEM上，我们在这里对上述方法进行总结，给出算法如\ref{LUT-M}所示，假设M和N都为4096，那么激活向量大小为4KB，32bit的结果向量的大小为16KB，转成对应的FP8向量需要占用4KB的空间，但是可以直接覆盖写入激活向量以节省空间，将查找表分成16份，每个子查找表的大小为16KB，载入的矩阵一行的大小为4KB，FP8到int32的映射表大小为1KB，总共占用WRAM空间41KB，剩余23KB给各个线程分配堆栈空间完全足够用。在这种设计下，权重矩阵的所有行总共只需要从MRAM中载入WRAM中一次，LUT的每个子表同样也只载入一次，FP8和int32的相互映射也是直接在WRAM中完成，充分提高了数据的重用性。

\section{基于缓存的矩阵行列重排算法}
UPMEM访问WRAM的速度较快，当流水线充满时，且访问带宽不受访问模式影响（顺序、随机），且任何8byte以下的数据访问都只会消耗一个时钟周期\cite{BenchmarkingMutlu}。在上一小节主要针对MRAM的读写做了优化，提高了WRAM的数据局部性，这一小节主要针对WRAM做优化，提高寄存器的数据重用。

\subsection{矩阵行重排}

\begin{figure}[!htbp]
	\centering
    \includegraphics[width=0.9\textwidth]{figures/LUTRow.pdf}
	\caption{矩阵行重排计算示意图}
    \label{LUTRow}
\end{figure}

针对算法\ref{LUT-M}，可以观察到每完成权重矩阵的一行计算就要读写各一次结果向量，有很大的开销，这里基于此前提到的算法做出修改如图\ref{LUTRow}所示，此前由于考虑权重矩阵一行的向量会较长无法同时载入多行，在这里可以依据激活向量的值的分布对权重矩阵进行分块，划分成BR（Block Row）行BC（Block Column）列的子矩阵。

\begin{algorithm}[!htbp]
    \caption{行重排的矩阵向量乘算法（LUT-W-R）}
    \label{LUT-W-R}
    \begin{algorithmic}[1]
        \Require $Vector[M], Matrix[M][N], LUT[256][256], MapLUT[256], BR, BC$; % input
        \Ensure $Result\_8[N]$; % output

        \State $\textbf{define}\; SubLUT[16][256],\;SubMat[BR][BC],\;Result\_32[N]$
        
        \For{$i \gets 0$ \textbf{to} $15$}
            \State $\textbf{mram\_read}(SubLUT, LUT[16i \cdots 16i + 15], 16K)$
            \Comment{\textcolor{blue}{parallel read}}

            \State $\textbf{define}\; Offset[BR],\;Index[BR],\;vidx=0$
            \While{$vidx < M$}
                \State $row \gets 0$
                \While{$row < BR$ \textbf{and} $vidx < M$}
                \Comment{\textcolor{blue}{parallel in BR for each tasklet}}
                    \If{$Vector[vidx] \;\textbf{in}\; [16i, 16i+15]$}
                        \State $Index[row] \gets vidx,\;row \gets row + 1$
                        \State $Offset[row-1] \gets SubLUT[Vector[vidx] \& \text{0xF}]$
                    \EndIf
                    \State $vidx \gets vidx + 1$
                \EndWhile
                \For{$j = 0$ \textbf{to} $N - 1$ \textbf{step} $BC$}
                    \For{$k = 0$ \textbf{to} $\text{row} - 1$}
                    \Comment{\textcolor{blue}{parallel in BR for each tasklet}}
                        \State $\textbf{mram\_read}(SubMat[k], \&Matrix[Index[k]][j], BC)$
                    \EndFor
                    \For{$k = j$ \textbf{to} $j + BC - 1$}
                    \Comment{\textcolor{blue}{parallel in BC for each tasklet}}
                        \State $temp \gets Result\_32[k]$
                        \For{$l = 0$ \textbf{to} $row - 1$}
                            \State $temp \gets temp + *(Offset[l] + SubMat[l][k] \times ele\_width)$
                        \EndFor
                        \State $Result\_32[k] \gets temp$
                    \EndFor
                \EndFor
            \EndWhile
        \EndFor

        % 调用二分查找函数
        \State $Result\_8 \gets \textbf{BinarySearch}(Result\_32, MapLUT)$
        \Comment{\textcolor{blue}{parallel in N}}
        \State \Return $Result\_8$
    \end{algorithmic}
\end{algorithm}

对于子矩阵，可以一次性全部载入，进而使用GEMV的内积计算方式，将结果向量某个元素的值缓存在寄存器中，完成了子矩阵的一列计算后再写入内存 。注意这里不改变矩阵的行列主存格式，依然按照行主存，原因是这里不真实地对矩阵的行进行重排，仅仅是在载入时挑选满足需求的子矩阵行，称之为虚拟重排（Virtually Reordered）。因此行之间不一定是连续的，改为列主存的话无法充分利用DMA引擎的大批量连续数据传输带宽高的特性，好在WRAM的访存模式对访存带宽并无影响，这里仍然按照列进行访存和计算，将子矩阵的一列和对应的激活向量进行向量内积操作，结果加到结果向量对应位置中。每次载入子查找表，就以BR行的粒度载入BC列的子矩阵，当该BR行的所有子矩阵完成了计算后，取寻找下一个BR行的子矩阵直至结束激活向量的所有访问。

具体如算法\ref{LUT-W-R}所示，设置M和N都为4096，且一次性载入的子矩阵大小上限为16KB，可以将BR和BC都设置为128，此时新增的数据结构有子矩阵SubMat，占用空间16KB；有Index数组保存行索引，占用256B；有Offset数组用于保存该行查找表的偏移，占用1KB空间，因此一共多占用了近13KB的WRAM的空间，相比于算法\ref{LUT-M}剩余8KB的空间，分配给各个线程的堆栈足够了。在使用行重排之前，每一行矩阵的计算都要读写各一次4096维度的结果向量。而使用了行重排之后，假设每次子矩阵都是128行，那么每128行才会读写各一次4096维度的向量，单就读写结果向量的提升来说，是128倍。当然每次处理矩阵元素时，不仅仅只做读写向量的操作，还包括读取矩阵元素、查表、相加以及其中隐含的算术逻辑操作，实际提升需要进一步测试。

\subsection{矩阵列重排}
同样针对算法\ref{LUT-M}，可以观察到，当激活向量中的某个元素和权重矩阵的一行做乘积时，需要频繁地查找子查找表以获取乘积，然而由于矩阵权重的每个元素为8bit，总共只有256种值，对应的乘积也只有256种值，因此理论上最多只需要查询256次LUT，但是实际的计算情况是矩阵一行中的每一个元素都重新去查询LUT，一共查询了4096次。如果将矩阵的一行按照数值排序，相同的连续数值只需要查表一次，这样就能避免重复查询LUT，提高访存效率。

按照此思想，我们提出列重排如图\ref{LUTCol:Construct}所示，为方便展示工作原理，这里以3bit数据位宽和一个16元素的向量为例，对于权重矩阵的每一行，首先我们保留其索引值，按照元素值进行排序，排序后我们构建一个8个元素的桶（数组）对应3bit数据的所有取值情况，对权重矩阵每一行0-7数值出现的次数进行计数，计数完成的这8个桶，我们称之为Delim数组，$Delim[i]$代表的含义就是值为i的元素出现的次数；接下来设置状态转移方程\ref{DelimDP}。

\begin{equation}
    \text{delim}[i] = \begin{cases}
        \text{delim}[i] - 1, & i = 0 \\
        \text{delim}[i] + \text{delim}[i - 1], & i > 0
    \end{cases}
    \label{DelimDP}
\end{equation}

这样更新之后，Delim才被真正称之为分界数组，然后再将排序后的索引构成的Index数组替换为权重矩阵对应的行向量即可。这个时候Delim数组的值就是指示着矩阵元素值发生变化的分界线。使用这样两个数据结构进行GEMV运算，如果确定了激活向量的元素的值V为2后，相当于确定了要查找的子查找表（查找表的某一行），然后读取Delim数组可以知道，Index数组的索引$(0,7]$的元素值都是1，因此可以通过查找LUT确定这个7个数的乘积都为1（uint8查找表），再读取载入的Index数组确定累加到结果向量的索引完成计算。

\begin{figure}[htbp!]
	\centering
	\subfigure[列重排Index和Delim数组构建]{
		\includegraphics[width=0.5\textwidth]{figures/LUTCol.pdf}
		\label{LUTCol:Construct}}
	\subfigure[列重排并行计算优化]{
		\includegraphics[width=0.4\textwidth]{figures/LUTColParallel.pdf}
        \label{LUTCol:Parallel}}
	\caption{矩阵列重排计算示意图}
    \label{LUTCol}
\end{figure}

但是由于数据的分布情况未知，简单按照Delim长度平均分配给各个线程的任务可能出现严重的负载不均，无法充分利用DPU的并行计算能力。可以看到图\ref{LUTCol:Parallel}中，这16个元素的向量交由4个tasklet进行数据划分执行GEMV，如果按照简单地Delim数组长度平均分，即tasklet0负责Delim数组中索引0和1的计算，tasklet1负责2和3等等，那么就出现负载不均衡：tasklet0负责了8个元素的计算，几乎占据了整个向量计算量的一半，而其他tasklet的计算量非常低，甚至有些只有两个元素的计算量，这些tasklet计算完成后就会被闲置等待tasklet0完成工作。

\begin{algorithm}[!htbp]
    \caption{列重排的矩阵向量乘算法（LUT-W-C）}
    \label{LUT-W-C}
    \begin{algorithmic}[1]
        \Require $Vector[M], DelimMat[M][TN][257], IndexMat[M][N], LUT[256][256], MapLUT[256]$; % input
        \Ensure $Result\_8[N]$; % output

        \State $\textbf{define}\; SubLUT[16][256],\;IndexRow[N],\;Delim[257],\;Result\_32[N]$

        \For{$i \gets 0$ \textbf{to} $15$}
            \State $\textbf{mram\_read}(SubLUT, LUT[16i \cdots 16i + 15], 16K)$
            \Comment{\textcolor{blue}{parallel read}}
            \For{$j \gets 0$ \textbf{to} $M - 1$}
                \If{$Vector[j] \;\textbf{not in}\; [16i, 16i+15]$}
                    \State \textbf{continue}
                \EndIf
                
                \State $\textbf{mram\_read}(IndexRow, IndexMat[j], 2N)$
                \Comment{\textcolor{blue}{parallel read}}
                \State $\textbf{mram\_read}(Delim, DelimMat[j][TaskletId], 514)$

                \State $k \gets Delim[0]$
                \While{$Delim[k] \neq -1$}
                    \State $product \gets SubLUT[Vector[j] \& \text{0xF}][k]$
                    \For{$l \gets (\textbf{if } k=0 \textbf{ then } 0 \textbf{ else } Delim[k-1]+1)$ \textbf{to} $Delim[k]$}
                        \State $Result[IndexRow[l]] \gets Result[IndexRow[l]] + product$
                    \EndFor
                    \State $k \gets k + 1$
                \EndWhile
            \EndFor
        \EndFor

        % 调用二分查找函数
        \State $Result\_8 \gets \textbf{BinarySearch}(Result\_32, MapLUT)$
        \Comment{\textcolor{blue}{parallel in N}}
        \State \Return $Result\_8$
    \end{algorithmic}
\end{algorithm}

回到实际情况，试想一种极端情况：权重矩阵的某一行4096个元素，值全部都是1，这样所有的计算任务都会交由tasklet0执行，其他线程需要等待tasklet0计算完成才能进行下一行的计算，性能会大大降低。因此为了负载均匀，需要重新设计Delim数组的形式：为每个tasklet配备一个Delim数组，然后将任务均分到每个tasklet独享的Delim数组中。

如图\ref{LUTCol:Parallel}所示，将前4个元素的计算分给tasklet0，则tasklet0需要执行一个值为0的计算和三个值为1的计算，那么只需要在Delim数组的0号索引填0，一号索引填3即可，在二号索引填-1表示任务结束不用继续读取Delim数组；tasklet1负责5-8号元素的计算，需要执行四个值为1的计算，只需要在一号索引填7，Start Index处填1表示任务起始的计算值，这样tasklet1就会从1号索引的前一号索引读取起始位置为3+1=4，然后读取4、5、6、7号元素执行计算。其他的tasklet类似。如此以来就能避免负载不均衡的问题。给出对应的算法\ref{LUT-W-C}。

假使M和N都为4096，相比算法\ref{LUT-M}，MRAM中多了DelimMat，Matrix变为IndexMat，因为需要记录索引因此矩阵的元素从一字节变为两字节。MRAM仍然足够，当TN（TaskletNum）为16时，WRAM中多了16个Delim数组，大概占用8KB的空间，且MatRow变为IndexRow多占用4KB空间，一共多占用12KB，总共占用WRAM空间53KB，剩余11KB给16个线程分配堆栈空间足够。同时每个tasklet在处理一行矩阵时由原来的4096次查表，变成了现如今最多256次查表，仅仅只是多读取了一个Delim数组，每行矩阵大概由原本的8K WRAM reads变为4.5K WRAM reads，差不多有两倍的性能提升。和此前算法\ref{LUT-W-R}类似，实际过程中查表操作的占比未知，提升需要进一步测试。

\section{本章小结}
本章主要是介绍了在近存计算UPMEM硬件上对GEMV算子的软件优化。首先简要提及了基于查找表的量化手段，介绍了查找表卸载二元算术运算基础。在此基础上提出针对多级存储访存优化的矩阵向量乘算法LUT-M，该算法使用查找表的方法卸载了FP8数据格式的乘法和加法的二元运算，拥有非常好的WRAM数据局部性。随后，更进一步提出了针对缓存访存优化的矩阵向量乘算法，分别对矩阵进行行重排（LUT-W-R）和列重排（LUT-W-C），充分考虑GEMV计算中WRAM的访问模式，优化寄存器局部性，减少无意义的内存读写。