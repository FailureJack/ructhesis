\chapter{总结与展望}
本章将对全文内容进行总结与展望。首先是对全文的设计进行简要介绍，接着分析了现有研究工作的不足，提出了未来研究和改进的空间。
\section{总结}
本文主要是基于近存计算技术，针对优化大模型推理中最基本的算子矩阵向量乘做出优化和研究。首先是介绍大模型推理加速和近存计算的相关工作，包括大模型推理的基本概念、大模型量化的相关工作以及矩阵向量乘的相关优化手段，介绍了近存计算的发展历程，详细介绍了商用近存计算硬件UPMEM的硬件架构和特性，以及基于UPMEM的相关应用，重点介绍了UPMEM被用于加速神经网络的相关文献。

基于上述文献调查，我们在商用近存计算硬件上设计了基于查找表的矩阵向量乘的相关算法。首先我们针对UPMEM的MRAM层级设计了算法LUT-M，通过分块载入查找表减少通过DMA传输数据到WRAM的次数，充分优化了WRAM的数据局部性。随后我们进一步针对UPMEM更高速的存储层级WRAM设计了矩阵行列重排算法LUT-W-R和LUT-W-C。通过矩阵行重排，将矩阵分块载入，减少做GEMV的累加操作时频繁地读写结果向量；通过矩阵列重排，按照权重值重排构造分界数组，减少每一行矩阵计算时的查表次数。这两种基于WRAM的算法都优化了寄存器数据的局部性，减少了对WRAM的访问。

同时，我们测试每个上述软件算法在UPMEM上的执行CPU和内存带宽利用率，分析性能瓶颈为计算，普通的基于访存优化的算法难以解决。因为我们基于UPMEM时钟精确模拟器PIMulator修改硬件。首先我们增设新的硬件单元加入了对融合查表加法指令的支持：融合查表加法指令是将查表操作（包括计算内存地址和访存）和累加操作融合到一条指令中，通过减少指令数量和融合指令执行加速算法。然后我们增加了向量单元以支持部分SIMD指令，使用SIMD指令的重排操作可以方便快速地进行多个乘法查表，同时以向量加法和向量位移指令辅助，可以大大提升访存和累加效率。

为了测试上说优化效果，在三个硬件平台CPU、GPU、UPMEM上我们设计了详尽的实验。首先我们测试GEMV算子的总吞吐，我们用计算量与执行时间的比值得到吞吐指标，在UPMEM上能达到355GOPS，是理论性能的93\%，是CPU平台总吞吐的14.7倍有较大提升。同时测试各个平台的能效比，用吞吐与功耗的比值标识，结果表明UPMEM的能耗比大概是CPU平台的8.6倍，是GPU平台的1.13倍，充分发挥了UPMEM近存计算硬件的优势。

\section{展望}
本文在商用近存计算硬件UPMEM上卸载矩阵向量乘算子，提出了一系列的基于查找表的优化方法，并在UPMEM模拟器PIMulator上做出了硬件架构的修改，总体工作使得GEMV算子在UPMEM上的吞吐量表现较好。但是上述工作仍然有局限性和需要改进的地方，总结为以下几点：
\begin{itemize}
	\item [1）]
	基于PIMulator的UPMEM硬件修改和探索不够深入。本文的工作对主要对硬件做了两处修改，包括增加融合查表指令和向量指令，更多地是基于指令集的简单修改，试图改善UPMEM计算瓶颈的问题，但是没有更多探索新的硬件架构诸如英伟达GPU的编程模型SIMT，或者将传统CPU常见的超标量、超流水、乱序等技术引入UPMEM的架构中来，以及WRAM和MRAM的DMA传输引擎的分析和优化空间等等，都是值得深入探究的问题。
	\item [2）]
	实验测试不够详尽。例如PIMulator提供了更加细粒度的执行时间breakdown，可以将DPU计算过程中访问寄存器的时间、多级流水调度的时间统计出来，可以更细粒度的探究性能瓶颈所在。
\end{itemize}