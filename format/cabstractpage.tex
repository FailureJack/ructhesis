% the abstract
\begin{abstractzh}
大语言模型在多个领域的成功应用推动了人工智能发展，但其存在计算成本高、内存需求大等缺点，优化其推理效率、降低资源消耗成核心问题。主流大模型多为Decoder-Only 架构，推理生成分预填充和生成两阶段，其中 GEMV 算子在大模型推理中占主导地位，是主要性能瓶颈。GEMV 因自身特点为内存瓶颈任务，使 GPU 等硬件利用率低，在边端场景下常成系统瓶颈。存内计算是新兴计算范式，能解决传统架构内存瓶颈问题，UPMEM 作为较成熟商用存算一体硬件，有高带宽、高存储、高并行性、高能效等优势，也存在计算能力弱、通信开销大等局限。如何从软件角度适配硬件加速，以及如何修改设计硬件优化其应用性能的软硬协同优化方案成为待深入研究的课题。本论文基于 UPMEM 硬件研究算子 GEMV 的软硬协同加速方案：设计基于查找表的向量矩阵乘法避免浮点乘法运算，通过分块载入查找表到高速内存减少DMA 访问次数增强高速内存的数据局部性，进行矩阵和向量的行列重排适应不同大小的矩阵减少访问查找表的次数并减少数据从寄存器流出，增强寄存器的数据局部性；同时基于 UPMEM 的周期精确模拟器 uPimulator 修改硬件，增加查找表专用 FMA 指令用于高效快速查询乘积并累加，设计基于查找表的SIMD指令进行向量化的查表和访存。最后对软硬协同优化设计了详细的基本测试，分别在 CPU 和GPU 以及 UPMEM 三个平台上，进行了包括对总 GEMV 算子计算性能的测试和详尽优化细分测试（breakdown）测试，此外还根据硬件特性做了扩展性测试和能效比测试，充分论证软硬协同优化的有效性。
\end{abstractzh}