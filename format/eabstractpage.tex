% the abstract
\begin{abstracten}
The successful application of large language models in multiple fields has driven the development of artificial intelligence. However, they have disadvantages such as high computational costs and large memory requirements. Optimizing their inference efficiency and reducing resource consumption have become core issues. Most mainstream large models are of the Decoder-Only architecture, and the inference generation is divided into pre-filling and generation stages. Among them, the GEMV operator dominates in the inference of large models and is the main performance bottleneck. Due to its own characteristics, GEMV is a memory bottleneck task, which leads to low utilization of hardware such as GPUs and often becomes a system bottleneck in edge scenarios. In-memory computing is an emerging computing paradigm that can solve the memory bottleneck problem of traditional architectures. UPMEM, as a relatively mature commercial in-memory computing hardware, has advantages such as high bandwidth, high storage, high parallelism, and high energy efficiency, but it also has limitations such as weak computing power and high communication overhead. How to adapt hardware acceleration from a software perspective and how to modify the design of hardware to optimize its application performance through a software-hardware collaborative optimization scheme have become topics for in-depth research. This paper studies the software-hardware collaborative acceleration scheme of the GEMV operator based on UPMEM hardware: designing a vector-matrix multiplication based on lookup tables to avoid floating-point multiplication operations, reducing the number of DMA accesses by loading lookup tables in blocks to high-speed memory to enhance the data locality of high-speed memory, and rearranging the rows and columns of matrices and vectors to adapt to matrices of different sizes to reduce the number of accesses to lookup tables and the outflow of data from registers, enhancing the data locality of registers; at the same time, modifying the hardware based on the cycle-accurate simulator uPimulator of UPMEM, adding a dedicated FMA instruction for lookup tables to efficiently and quickly query products and accumulate, and designing SIMD instructions based on lookup tables for vectorized lookup and memory access. Finally, detailed basic tests were designed for the software-hardware collaborative optimization, including tests on the overall GEMV operator computing performance and detailed optimization breakdown tests on three platforms: CPU, GPU, and UPMEM. In addition, scalability tests and energy efficiency ratio tests were conducted based on hardware characteristics to fully demonstrate the effectiveness of the software-hardware collaborative optimization.
\end{abstracten}
