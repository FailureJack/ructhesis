% the abstract
\begin{abstracten}
The successful application of large language models (LLMs) in multiple domains has propelled the advancement of artificial intelligence. Nevertheless, they suffer from drawbacks such as high computational costs and substantial memory demands. Optimizing their inference efficiency and reducing resource consumption have emerged as core issues. The majority of mainstream LLMs adopt the Decoder-Only architecture, within which the matrix-vector multiplication operator (GEMV) plays a dominant role in large model inference. Due to its inherent characteristics, GEMV constitutes a memory bounded task, with a low utilization of computing-intensive hardware like GPUs, often becoming a system bottleneck in edge scenarios. Processing-in-Memory (PIM) represents an emerging computing paradigm capable of resolving the memory bottleneck problem of traditional computing architectures. UPMEM, as a relatively mature commercial PIM hardware, boasts advantages such as high bandwidth, high storage capacity, high parallelism, and high energy efficiency. However, it also has limitations including weak computing power and significant communication overhead. How to adapt to hardware acceleration from a software perspective and how to modify the design of hardware to optimize its application performance through a hardware-software codesign have become subjects warranting in-depth investigation.

This thesis focuses on the hardware-software codesign of the operator GEMV based on PIM technology and UPMEM hardware: 1) On commercial hardware, a matrix-vector multiplication algorithm based on lookup tables is devised to eliminate complex computations using lookup tables. Simultaneously, memory access optimizations are implemented for the two-level storage structure (WRAM, MRAM) in UPMEM hardware. This includes a lookup table block algorithm to reduce the number of DMA accesses to MRAM and the rearrangement of the rows and columns of the matrix to minimize accesses to WRAM, enhancing data locality in registers. 2) On the simulator, to address the computational bottleneck of software algorithms on UPMEM, the cycle-accurate simulator PIMulator for UPMEM is modified to enhance its computing capability. This encompasses adding a fused lookup table addition (FLA) instruction for efficient and rapid product lookup and accumulation, as well as designing a lookup table-based SIMD instruction for vectorized memory access to improve computing efficiency. Finally, detailed tests were conducted on the aforementioned algorithms on three hardware platforms: CPU, GPU, and UPMEM, including tests on the total throughput and energy efficiency ratio of the GEMV operator. The experimental results indicate that on the UPMEM platform, the throughput of the GEMV operator is 355 GOPS, approximately reaching 93\% of the theoretical performance. It is 14.7 times that of the CPU platform and 1.13 times that of the GPU platform. The energy efficiency ratio is approximately 8.6 times that of the CPU platform and 1.13 times that of the GPU platform. 
\end{abstracten}
